# -*- coding: utf-8 -*-
"""Statistics_for_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TW9aLZNeh-u19q6mB8tBjzhD01_LnKOx

#I. Basic Probability

Question 1:
"""

import numpy as np

def compute_mean(x):
  total = 0
  for _ in x:
    total +=_
  return total/len(x)

X = [2, 0, 2, 2, 7, 4, -2, 5, -1, -1]
print(compute_mean(X))

"""Question 2:

"""

def compute_median(x):
  size = len(x)
  x = np.sort(x)
  if (size%2) == 0:
    return (x[int(size/2)]+x[int(size/2)-1])/2
  else:
    return x[int((size+1)/2)]

X = [1, 5, 4, 4, 9, 13]
print(compute_median(X))

"""Question 3:"""

def compute_std(x):
  mean = compute_mean(x)
  variance = 0
  for _ in x:
    variance += (_ - mean)**2
  variance = variance/len(x)
  return np.sqrt(variance)

X = [171, 176, 155, 167, 169, 182]
print(compute_std(X))

"""Question 4:"""

def compute_covariance(x, y):
  N = len(x)
  x_mean = compute_mean(x)
  y_mean = compute_mean(y)
  numerator = 0
  denominator = 0
  for i in range(N):
    numerator += (x[i]-x_mean)*(y[i]-y_mean)
  denominator += N
  return np.round(numerator/denominator, 2)

x = np.array([1, 3, 4, 4])
y = np.array([1, 2, 3, 2])
print("Covariance:", compute_covariance(x, y))

def compute_correlation_coefficient(x, y):
  N = len(x)
  x_var = compute_std(x)
  y_var = compute_std(y)
  numerator = 0
  denominator = 0
  numerator += compute_covariance(x, y)
  denominator += x_var*y_var
  return np.round(numerator/denominator, 2)

X = np.asarray([-2, -5, -11, 6, 4, 15, 9])
Y = np.asarray ([4, 25, 121, 36, 16, 225, 81])
print("Correlation:", compute_correlation_coefficient(X, Y))

"""#II. Tabular Data Analysis

Question 5:
"""

!gdown 1iA0WmVfW88HyJvTBSQDI5vesf-pgKabq

import pandas as pd

data = pd.read_csv('advertising.csv')

def Correlation(x, y):
  numerator = 0
  denominator = 0
  numerator += compute_covariance(x, y)
  denominator += compute_std(x)*compute_std(y)
  return np.round(numerator/denominator, 2)

x = data['TV']
y = data['Radio']
corr_xy = Correlation(x, y)
print(f"Correlation between TV and Radio: {round(corr_xy, 2)}")

"""Question 6:"""

import pandas as pd

data = pd.read_csv('advertising.csv')

def Correlation(x, y):
  numerator = 0
  denominator = 0
  numerator += compute_covariance(x, y)
  denominator += compute_std(x)*compute_std(y)
  return np.round(numerator/denominator, 2)

features = ['TV', 'Radio', 'Newspaper']

for feature_1 in features:
  for feature_2 in features:
      correlation_value = Correlation(data[feature_1], data[feature_2])
      print( f" Correlation between {feature_1} and {feature_2}: {round(correlation_value, 2)}")

"""Question 7:"""

data = pd.read_csv('advertising.csv')
x = data['Radio']
y = data['Newspaper']

result = np.corrcoef(x, y)
print(result)

"""Question 8:"""

data = pd.read_csv('advertising.csv')

print(data.corr())

"""Question 9:

"""

import matplotlib.pyplot as plt
import seaborn as sns
data = pd.read_csv('advertising.csv')

plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot = True, fmt = '.2f', linewidth = .5)
plt.show()

"""#Text Retrieval

Question 10:
"""

!gdown 1jh2p2DlaWsDo_vEWIcTrNh3mUuXd-cw6

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

vi_data_df = pd.read_csv('vi_text_retrieval.csv')
context = vi_data_df['text']
context = [doc.lower() for doc in context]

tfidf_vectorizer = TfidfVectorizer()
context_embedded = tfidf_vectorizer.fit_transform(context)
context_embedded.toarray()[7][0]

"""Question 11:"""

def tfidf_search(question, tfidf_vectorizer, top_d = 5):
  query_embedded = tfidf_vectorizer.transform([question.lower()])
  cosine_similarities = cosine_similarity(query_embedded, context_embedded).flatten()
  results = []
  for idx in cosine_similarities.argsort()[-top_d:][::-1]:
    doc_score = {
        'id' : idx,
        'cosine_score': cosine_similarities[idx]
    }
    results.append(doc_score)
  return results

question = vi_data_df.iloc[0]['question']
results = tfidf_search(question, tfidf_vectorizer, top_d =5)
results[0]['cosine_score']

"""Question 12:
  
"""

def corr_search(question, tfidf_vectorizer, top_d = 5):
  query_embedded = tfidf_vectorizer.transform([question.lower()])
  cosine_similarities = cosine_similarity(query_embedded, context_embedded).flatten()
  corr_scores = np.corrcoef(query_embedded.toarray(), context_embedded.toarray())
  corr_scores = corr_scores[0][1:]
  results = []
  for idx in corr_scores.argsort()[-top_d:][::-1]:
    doc_score = {
        'id' : idx,
        'corr_score': corr_scores[idx]
    }
    results.append(doc_score)
  return results

question = vi_data_df.iloc[0]['question']
results = corr_search(question, tfidf_vectorizer, top_d =5)
results[1]['corr_score']